{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.feature_column import SparseFeat, get_feature_names, DenseFeat\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "data = pd.read_csv('./data/criteo/criteo_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 40 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   click   100000 non-null  int64 \n",
      " 1   int_1   100000 non-null  int64 \n",
      " 2   int_2   100000 non-null  int64 \n",
      " 3   int_3   100000 non-null  int64 \n",
      " 4   int_4   100000 non-null  int64 \n",
      " 5   int_5   100000 non-null  int64 \n",
      " 6   int_6   100000 non-null  int64 \n",
      " 7   int_7   100000 non-null  int64 \n",
      " 8   int_8   100000 non-null  int64 \n",
      " 9   int_9   100000 non-null  int64 \n",
      " 10  int_10  100000 non-null  int64 \n",
      " 11  int_11  100000 non-null  int64 \n",
      " 12  int_12  100000 non-null  int64 \n",
      " 13  int_13  100000 non-null  int64 \n",
      " 14  cat_1   100000 non-null  string\n",
      " 15  cat_2   100000 non-null  string\n",
      " 16  cat_3   100000 non-null  string\n",
      " 17  cat_4   100000 non-null  string\n",
      " 18  cat_5   100000 non-null  string\n",
      " 19  cat_6   100000 non-null  string\n",
      " 20  cat_7   100000 non-null  string\n",
      " 21  cat_8   100000 non-null  string\n",
      " 22  cat_9   100000 non-null  string\n",
      " 23  cat_10  100000 non-null  string\n",
      " 24  cat_11  100000 non-null  string\n",
      " 25  cat_12  100000 non-null  string\n",
      " 26  cat_13  100000 non-null  string\n",
      " 27  cat_14  100000 non-null  string\n",
      " 28  cat_15  100000 non-null  string\n",
      " 29  cat_16  100000 non-null  string\n",
      " 30  cat_17  100000 non-null  string\n",
      " 31  cat_18  100000 non-null  string\n",
      " 32  cat_19  100000 non-null  string\n",
      " 33  cat_20  100000 non-null  string\n",
      " 34  cat_21  100000 non-null  string\n",
      " 35  cat_22  100000 non-null  string\n",
      " 36  cat_23  100000 non-null  string\n",
      " 37  cat_24  100000 non-null  string\n",
      " 38  cat_25  100000 non-null  string\n",
      " 39  cat_26  100000 non-null  string\n",
      "dtypes: int64(14), string(26)\n",
      "memory usage: 30.5 MB\n"
     ]
    }
   ],
   "source": [
    "sparse_features = [f'cat_{i}' for i in range(1,27)]\n",
    "dense_features = [f'int_{i}' for i in range(1,14)]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', ).astype('string')\n",
    "data[dense_features] = data[dense_features].fillna(0,).astype('int64')\n",
    "target = ['click']\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple preprocessing\n",
    "\n",
    "In this step we scale the numerical features. Sparse categorical features are encoded on the fly in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash encoding on the fly\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=100,embedding_dim=4, use_hash=True, dtype='string')  # the input is string\n",
    "                              for feat in sparse_features] + [DenseFeat(feat, 1, )\n",
    "                          for feat in dense_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature columns\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the training samples and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training samples\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = {name: train[name] for name in feature_names}\n",
    "test_model_input = {name: test[name] for name in feature_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = DeepFM(linear_feature_columns,dnn_feature_columns,task='binary')\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=['binary_crossentropy',AUC()], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "640/640 [==============================] - 73s 86ms/step - loss: 0.5372 - binary_crossentropy: 0.5371 - auc: 0.6602 - val_loss: 0.5086 - val_binary_crossentropy: 0.5085 - val_auc: 0.7218\n",
      "Epoch 2/10\n",
      "640/640 [==============================] - 47s 74ms/step - loss: 0.4900 - binary_crossentropy: 0.4899 - auc: 0.7440 - val_loss: 0.5053 - val_binary_crossentropy: 0.5052 - val_auc: 0.7269\n",
      "Epoch 3/10\n",
      "640/640 [==============================] - 58s 91ms/step - loss: 0.4792 - binary_crossentropy: 0.4790 - auc: 0.7607 - val_loss: 0.5048 - val_binary_crossentropy: 0.5046 - val_auc: 0.7265\n",
      "Epoch 4/10\n",
      "640/640 [==============================] - 74s 116ms/step - loss: 0.4666 - binary_crossentropy: 0.4663 - auc: 0.7762 - val_loss: 0.5145 - val_binary_crossentropy: 0.5142 - val_auc: 0.7219\n",
      "Epoch 5/10\n",
      "640/640 [==============================] - 44s 68ms/step - loss: 0.4480 - binary_crossentropy: 0.4476 - auc: 0.7985 - val_loss: 0.5231 - val_binary_crossentropy: 0.5226 - val_auc: 0.7182\n",
      "Epoch 6/10\n",
      "640/640 [==============================] - 47s 74ms/step - loss: 0.4297 - binary_crossentropy: 0.4292 - auc: 0.8188 - val_loss: 0.5307 - val_binary_crossentropy: 0.5301 - val_auc: 0.7108\n",
      "Epoch 7/10\n",
      "640/640 [==============================] - 42s 65ms/step - loss: 0.4030 - binary_crossentropy: 0.4024 - auc: 0.8437 - val_loss: 0.5597 - val_binary_crossentropy: 0.5590 - val_auc: 0.7021\n",
      "Epoch 8/10\n",
      "640/640 [==============================] - 40s 63ms/step - loss: 0.3812 - binary_crossentropy: 0.3805 - auc: 0.8642 - val_loss: 0.5928 - val_binary_crossentropy: 0.5919 - val_auc: 0.6916\n",
      "Epoch 9/10\n",
      "640/640 [==============================] - 45s 70ms/step - loss: 0.3534 - binary_crossentropy: 0.3525 - auc: 0.8852 - val_loss: 0.6112 - val_binary_crossentropy: 0.6102 - val_auc: 0.6860\n",
      "Epoch 10/10\n",
      "640/640 [==============================] - 41s 65ms/step - loss: 0.3227 - binary_crossentropy: 0.3217 - auc: 0.9042 - val_loss: 0.6339 - val_binary_crossentropy: 0.6328 - val_auc: 0.6749\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(train_model_input, train[target].values, batch_size=100,epochs=10, validation_split=0.2, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
